# Sistema A Scraper - GitHub Actions

Este workflow ejecuta autom√°ticamente el scraper de inventario de Sistema A usando Playwright en GitHub Actions y sube los datos al servidor.

## üìÖ Horario de Ejecuci√≥n

- **Frecuencia**: Cada hora (13 veces al d√≠a)
- **D√≠as**: Lunes a Viernes
- **Horario**: 7:00 AM - 7:00 PM (hora Costa Rica)
- **Cron**: `0 13-22 * * 1-5` (UTC)

## üîê Secretos Requeridos

Debes configurar estos secretos en GitHub: **Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí New repository secret**

### 1. `SISTEMA_A_USER`
- **Descripci√≥n**: Usuario para login en Sistema A (Grupo Argus)
- **Ejemplo**: `usuario@ortomedica.com`

### 2. `SISTEMA_A_PASS`
- **Descripci√≥n**: Contrase√±a para Sistema A
- **Ejemplo**: `MiContrase√±aSegura123`

### 3. `SERVER_HOST`
- **Descripci√≥n**: Hostname o IP del servidor donde se subir√° la base de datos
- **Ejemplo**: `sistema.ortomedicacr.com` o `IP_DEL_SERVIDOR`

### 4. `SERVER_USER`
- **Descripci√≥n**: Usuario SSH del servidor
- **Ejemplo**: `ortome5`

### 5. `SERVER_SSH_KEY`
- **Descripci√≥n**: Llave privada SSH para conectarse al servidor (formato completo, incluyendo BEGIN/END)
- **C√≥mo obtenerla**:
  ```bash
  # En tu m√°quina local, genera una nueva llave SSH para GitHub Actions:
  ssh-keygen -t rsa -b 4096 -f ~/.ssh/github_actions_key -N ""
  
  # Copia la llave P√öBLICA al servidor:
  ssh-copy-id -i ~/.ssh/github_actions_key.pub ortome5@sistema.ortomedicacr.com
  
  # Copia la llave PRIVADA (todo el contenido del archivo):
  cat ~/.ssh/github_actions_key
  ```
- **Formato**:
  ```
  -----BEGIN OPENSSH PRIVATE KEY-----
  b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAABlwAAAAdzc2gtcn
  ... (m√∫ltiples l√≠neas) ...
  -----END OPENSSH PRIVATE KEY-----
  ```

### 6. `SERVER_PATH`
- **Descripci√≥n**: Ruta absoluta donde se guardar√° `inventario.db` en el servidor
- **Ejemplo**: `/home/ortome5/sistema.ortomedicacr.com/sistema-ortomedica/backend`

## üöÄ Uso

### Ejecuci√≥n Manual
1. Ve a **Actions** en GitHub
2. Selecciona **"Sistema A Scraper (Playwright)"**
3. Click en **"Run workflow"** ‚Üí **"Run workflow"**
4. Espera ~3-5 minutos

### Ejecuci√≥n Autom√°tica
El workflow se ejecuta autom√°ticamente seg√∫n el horario configurado.

### Ver Resultados
1. **Actions** ‚Üí Click en la ejecuci√≥n m√°s reciente
2. Ver logs del job `scrape-and-upload`
3. Descargar artifact `inventario-db-XXX` si necesitas la base de datos local

## üìä Consumo de Minutos

- **Ejecuciones**: 13/d√≠a √ó 5 d√≠as = 65/semana ‚Üí ~281/mes
- **Tiempo por ejecuci√≥n**: ~5 minutos
- **Total mensual**: ~1,405 minutos
- **Plan gratuito**: 2,000 minutos/mes
- **Margen**: ~600 minutos disponibles ‚úÖ

## üîß Troubleshooting

### Error: "Login fall√≥"
- Verifica que `SISTEMA_A_USER` y `SISTEMA_A_PASS` sean correctos
- Sistema A puede tener captcha activado

### Error: "Permission denied (publickey)"
- Verifica que `SERVER_SSH_KEY` contenga la llave privada completa
- Verifica que la llave p√∫blica est√© en `~/.ssh/authorized_keys` del servidor

### Error: "No such file or directory"
- Verifica que `SERVER_PATH` sea la ruta correcta y exista

### Base de datos no se actualiza
- Verifica que el archivo `inventario.db` tenga permisos de escritura
- Verifica que el usuario SSH tenga permisos en la carpeta

## üìù Notas

- La base de datos se reemplaza **at√≥micamente** (primero `.new`, luego `mv`)
- Los artifacts se retienen **1 d√≠a** (ajustable en el workflow)
- El scraper limpia inventario previo antes de insertar nuevos datos
- Se bloquean recursos no esenciales (im√°genes, fonts) para acelerar scraping
